{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование на своем датасете: использование модели LDA, визуализация топиков, построение тематических профилей.\n",
    "Цель: Боевой проект по тематическому моделированию. Цель - построить LDA модель и получить интерпретируемые топики. Попробовать посчитать тематические профили и получить их визуализацию на двумерной плоскости при помощи TSNE\n",
    "В материалах вы можете найти выгрузку комментариев из разных музыкальных групп ВК, в полях music_style и performer можно получить информацию о конкретном музыкальном жанре и исполнителе, в группе которого был написан комментарий. Выгрузка уменьшенная, остались только комментарии длиной больше 40 слов, но тем не менее это всё ещё 500Мб, так что модельки будут считаться долго. Для отладки рекомендую брать небольшую выборку из этого датасета, чтобы на ней тестировать свой код.\n",
    "\n",
    "Если у вас есть собственный датасет - можно (и будет очень круто) использовать его :)\n",
    "\n",
    "1. Загрузите датасет. Если используете данные вк, то после загрузки воспользуйтесь следующим кодом:\n",
    "\n",
    "from ast import literal_eval\n",
    "bag_of_words = data.text_bow.apply(literal_eval)\n",
    "\n",
    "где data - это загруженный датасет. Операция необходима, так как предварительно уже была проведена предобработка текстов и получено представление bag-of-words, так что остаётся его лишь прочитать из датасета\n",
    "\n",
    "2. Используя gensim, добавьте биграммы к имеющемуся bag_of_words представлению\n",
    "\n",
    "3. Составьте словарь из терминов (corpora.Dictionary)\n",
    "\n",
    "4. По словарю терминов при помощи метода filter_extremes проведите фильтрацию слов по частоте встречаемости. На данных вк рекомендую следующие параметры: (no_below=3, no_above=0.4, keep_n=3*10**6)\n",
    "\n",
    "5. Наконец, составьте итоговый корпус документов при помощи метода doc2bow. Рекомендую его сохранить (например, в pickle формате), на случай, если что-то где-то пойдет не так\n",
    "\n",
    "6. По получившемуся корпусу постройте LDA модель, если используете данные вк, рекомендую параметры (eval_every=20, num_topics=30, passes=5). Не забудьте сохранить саму модель и её аттрибут expElogBeta, также при помощи метода show_topics возьмите по 100 самых вероятных слов для каждой темы\n",
    "\n",
    "7. При помощи wordcloud визуализируйте каждый из получившихся топиков и попробуйте их проинтерпретировать. Чтобы не возиться долго с функциями для визуализации, можно взять их отсюда - https://github.com/DmitrySerg/top-russian-music/blob/master/models/clean_visualization.ipynb\n",
    "\n",
    "8. Наконец, постройте тематические профили по интересующим вас группировкам (в случае с вк можно построить средние тематические вектора по жанрам или по исполнителям, если у вас собственные данные, попробуйте подумать, как можно было бы сгруппировать ваши документы, чтобы все-таки построить профили групп), и визуализируйте их при помощи TSNE\n",
    "\n",
    "9. Вы великолепны\n",
    "Критерии оценки: Получилось построить LDA и хотя бы в текстовом формате показать наиболее характерные для каждого топика слова - 5 баллов\n",
    "\n",
    "Есть визуализация wordcloud +2 балла\n",
    "\n",
    "Есть визуализация TSNE для тематических профилей +3 балла\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
